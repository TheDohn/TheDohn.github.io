{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.23.3', '0.9.0', '1.14.2')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context = 'notebook', #mostly controls relative sizes of things on plot #The base context is “notebook”, and the other contexts are “paper”, “talk”, and “poster”\n",
    "        style = 'darkgrid', #dict, None, or one of {darkgrid, whitegrid, dark, white, ticks}\n",
    "        palette = 'deep', # Should be something that color_palette() can process.\n",
    "        font_scale = 1, \n",
    "        color_codes = False, \n",
    "        rc = None)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell \n",
    "# InteractiveShell.ast_node_interactivity = 'last_expr' #s etting = \"all\" allows multiple outputs to be displayed for a given input cell. don't use w plotting!\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "\n",
    "pd.__version__, sns.__version__ , np.__version__ #,  matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     1,
     5
    ]
   },
   "outputs": [],
   "source": [
    "# some functions to load\n",
    "def head_with_full_columns(pd_in, row_amount = 5):\n",
    "    with pd.option_context('display.max_columns', len(pd_in.iloc[0])):\n",
    "        display(pd_in[:row_amount])\n",
    "        \n",
    "def balanced_sample(df_in, total_size, rand_state):\n",
    "    s0 = df_in[df_in['TARGET']==0].sample(n = total_size//2, random_state = rand_state)\n",
    "    s1 = df_in[df_in['TARGET']==1].sample(n = total_size//2, random_state = rand_state)\n",
    "    new_df = pd.concat([s0,s1])\n",
    "    new_df.sort_index(inplace = True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/DonBunk\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = 'Desktop/Google Drive/data_science/Python_Projects/Home_Credit_Default_Risk/raw_loan_data_from_Kaggle/'\n",
    "\n",
    "agg_data_path = 'Desktop/Google Drive/data_science/Python_Projects/Home_Credit_Default_Risk/aggregation/TRAIN_aggregation/'\n",
    "\n",
    "save_path = 'Desktop/Google Drive/data_science/Python_Projects/Home_Credit_Default_Risk/wrangling/TRAINING_DATA_create_final_wrangled_csv/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Wrangle  application_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_df = pd.read_csv(raw_data_path + 'application_train.csv', index_col = 'SK_ID_CURR')\n",
    "# AMT_ANNUITY appears in multiple files, so rename more specifically. \n",
    "application_train_df.rename(columns = {\"AMT_ANNUITY\":\"AMT_ANNUITY_from_app_train\"} , inplace=True) #index = str, \n",
    "\n",
    "#application_train_df.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## null counts feature, social_counts feature, THEN replace categorical NaNs -> 'NA's, combine cat features <1%. creat DAYS_EMPLOYED = 365243 feature, fix DAYS_EMPLOYED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# dropping some features\n",
    "\n",
    "# separate out certain features \n",
    "housing_feats = [f for f in application_train_df.columns if 'AVG' in f or 'MODE' in f or 'MEDI' in f]\n",
    "doc_feats = [f for f in application_train_df.columns if 'DOCUMENT' in f]\n",
    "social_circle_feats = [f for f in application_train_df.columns if 'SOCIAL' in f]\n",
    "amt_req_feats = [f for f in application_train_df.columns if 'AMT_REQ' in f]\n",
    "\n",
    "# in another notebook (application_less_important_features) I explore these feats and decide what to drop\n",
    "# this is a bit confusing: I am forming a list of features to drop from groups I made\n",
    "# and aubtract some features from those groups TO KEEP\n",
    "# I also add some individual features to drop\n",
    "\n",
    "groups_of_features_to_drop  = housing_feats + doc_feats + social_circle_feats+ amt_req_feats\n",
    "\n",
    "feats_to_not_drop = {'EMERGENCYSTATE_MODE', 'APARTMENTS_AVG', 'LANDAREA_AVG', 'TOTALAREA_MODE', # these have a bit of info in them\n",
    "                        'FLAG_DOCUMENT_3','FLAG_DOCUMENT_6', # these have a bit of info in them\n",
    "                        'OBS_60_CNT_SOCIAL_CIRCLE',   # there is no info here, but keeping it as representative feature \n",
    "                        'AMT_REQ_CREDIT_BUREAU_YEAR'  # there is not a lot of info here, but keeping it as representative feature \n",
    "                        }\n",
    "\n",
    "misc_feats_to_drop = ['FLAG_MOBIL',  # this doesn't have much info\n",
    "                        'FLAG_CONT_MOBILE', # this doesn't have much info\n",
    "                        'REGION_RATING_CLIENT_W_CITY' # this is HIGHLY correlated (~.95) with REGION_RATING_CLIENT_\n",
    "                        ]\n",
    "\n",
    "feats_to_drop = list( set(groups_of_features_to_drop) - set(feats_to_not_drop)) + misc_feats_to_drop\n",
    "\n",
    "\n",
    "application_train_df.drop(columns= feats_to_drop, inplace=True)\n",
    "\n",
    "del housing_feats\n",
    "del doc_feats\n",
    "del social_circle_feats\n",
    "del amt_req_feats\n",
    "del feats_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 49)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a null counts feature\n",
    "null_counts = application_train_df.isnull().sum(axis = 1)\n",
    "null_counts.rename('NULL_COUNTS', inplace=True);\n",
    "application_train_df = pd.concat([application_train_df, null_counts], axis = 1)\n",
    "del null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a null counts just for social features. which make have some corr with TARGET\n",
    "social_circle_feats = [f for f in application_train_df.columns if 'SOCIAL' in f]\n",
    "social_null_counts = application_train_df[social_circle_feats].isnull().sum(axis = 1)\n",
    "social_null_counts.rename('SOCIAL_NULL_COUNTS', inplace=True);\n",
    "application_train_df = pd.concat([application_train_df, social_null_counts], axis = 1)\n",
    "del social_circle_feats\n",
    "del social_null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaNs in object entries for now is pretty safe. \n",
    "f_list = list(application_train_df.select_dtypes('object').columns)\n",
    "application_train_df[f_list] = application_train_df[f_list].fillna(value = 'No/Av')\n",
    "del f_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for categorical feature than have more than one value <1%, condensed the <1% values and define a new condensed feature\n",
    "\n",
    "for feat in application_train_df.select_dtypes('object').columns:\n",
    "    percent_srs = application_train_df[feat].value_counts() /len(application_train_df[feat])\n",
    "    percent_less_than_1 = list(percent_srs[percent_srs <.01].index)\n",
    "    if len(percent_less_than_1)>1:\n",
    "        application_train_df[feat + '_condensed'] = application_train_df[feat].apply(lambda x: '<1%' if x in percent_less_than_1 else x)\n",
    "        application_train_df.drop(columns=[feat], inplace=True)\n",
    "      \n",
    "del feat\n",
    "del percent_srs\n",
    "del percent_less_than_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     2,
     20
    ]
   },
   "outputs": [],
   "source": [
    "# creat a DAYS_EMPLOYED = 365243 feature, and then regress away those values\n",
    "\n",
    "def make_days_empl_col(row):\n",
    "    if row['DAYS_EMPLOYED']== 365243:\n",
    "        return 'Y'\n",
    "    else:\n",
    "        return 'N'\n",
    "    \n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# have to make a list of lists, turn that into np.array, then transpose to has correct shape for the single feature(s) working w here. \n",
    "no_weird_vals_df = application_train_df[ application_train_df['DAYS_EMPLOYED'] !=365243]\n",
    "reg.fit(np.array([no_weird_vals_df['DAYS_BIRTH'].values]).T, no_weird_vals_df['DAYS_EMPLOYED'].values)\n",
    "\n",
    "# create a new binary column while I still have the 365243 values.\n",
    "application_train_df['DAYS_EMPLOYED_eq_365243'] = application_train_df.apply(make_days_empl_col, axis=1)\n",
    "\n",
    "# replace ['DAYS_EMPLOYED']==365243 with lin reg vals from above\n",
    "\n",
    "def fix_DAYS_EMPLOYED(row):\n",
    "    # fill in the weird values\n",
    "    if row['DAYS_EMPLOYED']== 365243:\n",
    "        return reg.predict( row['DAYS_BIRTH'] )[0] # need this [0] so it puts value and not a 1-dim array in place\n",
    "    # fill in any nans while we are at it\n",
    "    elif np.isnan(row['DAYS_EMPLOYED']):\n",
    "        return reg.predict( row['DAYS_BIRTH'] )[0] # need this [0] so it puts value and not a 1-dim array in place\n",
    "    else:\n",
    "        return row['DAYS_EMPLOYED']\n",
    "    \n",
    "application_train_df['DAYS_EMPLOYED'] = application_train_df.apply(fix_DAYS_EMPLOYED, axis = 1)\n",
    "\n",
    "del reg\n",
    "del no_weird_vals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## replacing NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# replace NaNs in CNT_FAMILY_MEMBERS and make it an int\n",
    "# need to replace NaNs bc pandas does not support NaNs in ints!\n",
    "\n",
    "replace_dict = {#'EXT_SOURCE_1':.5,\n",
    "                #'EXT_SOURCE_3':.5, # there are a lot of missing values, but as it stands it is hard to find anything better to impute with\n",
    "                'CNT_FAM_MEMBERS':application_train_df['CNT_FAM_MEMBERS'].median(), # not many missing, need an integer so use median\n",
    "                'AMT_ANNUITY_from_app_train':application_train_df['AMT_ANNUITY_from_app_train'].median(), # not many missing\n",
    "                'AMT_GOODS_PRICE': application_train_df['AMT_GOODS_PRICE'].median(), # not many missing\n",
    "                'DAYS_LAST_PHONE_CHANGE': application_train_df['DAYS_LAST_PHONE_CHANGE'].median(), # not many missing\n",
    "                'OWN_CAR_AGE':15, # eyeballed the car age that has equal TARGET = 0, 1 scores                 \n",
    "                'APARTMENTS_AVG':0, # A LOT MISSING, having a null here likely means 0 for someone filling out the form        \n",
    "                'LANDAREA_AVG':0, # A LOT MISSING, having a null here likely means 0 for someone filling out the form                  \n",
    "                'TOTALAREA_MODE':0, # A LOT MISSING, having a null here likely means 0 for someone filling out the form            \n",
    "                'OBS_60_CNT_SOCIAL_CIRCLE':0, # not many missing, having a null here likely means 0 for someone filling out the form          \n",
    "                'AMT_REQ_CREDIT_BUREAU_YEAR':0, # A LOT MISSING, having a null here likely means 0 for someone filling out the form    \n",
    "                }\n",
    "\n",
    "application_train_df.fillna(replace_dict, inplace=True)\n",
    "\n",
    "# convert this to int now that NaNs are gone, which it should be\n",
    "application_train_df['CNT_FAM_MEMBERS'] = application_train_df['CNT_FAM_MEMBERS'].astype(int)\n",
    "\n",
    "# this is a final catch all in case other missing values appear in test set\n",
    "#check_nan = application_train_df.isna().any() \n",
    "\n",
    "# replace_dict_EXTRA ={}\n",
    "# for f in check_nan[check_nan==True].index:\n",
    "#     replace_dict_EXTRA[f]=application_train_df[f].median()\n",
    "    \n",
    "# if replace_dict_EXTRA:\n",
    "#     print('There were additional replacements!')\n",
    "#     application_train_df.fillna(replace_dict_EXTRA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_1 = application_train_df[application_train_df['EXT_SOURCE_1'].isnull()][['CODE_GENDER','DAYS_BIRTH','EXT_SOURCE_1']].sample(n =5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_2 = application_train_df[application_train_df['EXT_SOURCE_2'].isnull()][['REGION_RATING_CLIENT','DAYS_BIRTH','EXT_SOURCE_2']].sample(n =5, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_3 = application_train_df[application_train_df['EXT_SOURCE_3'].isnull()][['DAYS_BIRTH','EXT_SOURCE_3']].sample(n =5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     13
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# this is a bit slow, but faster than only applying to nan values and then replacing in a loop \n",
    "male_df = application_train_df[application_train_df['CODE_GENDER']=='M'][['DAYS_BIRTH','EXT_SOURCE_1']]\n",
    "male_df = male_df[male_df['EXT_SOURCE_1'].notna()]\n",
    "m_s, m_i, r_value, p_value, std_err = stats.linregress(male_df)\n",
    "\n",
    "female_df = application_train_df[application_train_df['CODE_GENDER']=='F'][['DAYS_BIRTH','EXT_SOURCE_1']]\n",
    "female_df = female_df[female_df['EXT_SOURCE_1'].notna()]\n",
    "f_s, f_i, r_value, p_value, std_err = stats.linregress(female_df)\n",
    "\n",
    "nogender_df = application_train_df[['DAYS_BIRTH','EXT_SOURCE_1']]\n",
    "nogender_df = nogender_df[nogender_df['EXT_SOURCE_1'].notna()]\n",
    "ng_s, ng_i, r_value, p_value, std_err = stats.linregress(nogender_df)\n",
    "\n",
    "def EXT1_replace(row):\n",
    "    if np.isnan(row['EXT_SOURCE_1']) ==False:\n",
    "        return row['EXT_SOURCE_1']\n",
    "    else:\n",
    "        if row['CODE_GENDER']=='M':\n",
    "            return m_s*row['DAYS_BIRTH'] + m_i\n",
    "        if row['CODE_GENDER']=='F':\n",
    "            return f_s*row['DAYS_BIRTH'] + f_i\n",
    "        if row['CODE_GENDER']=='XNA':\n",
    "            return ng_s*row['DAYS_BIRTH'] + ng_i\n",
    "    \n",
    "application_train_df['EXT_SOURCE_1'] = application_train_df.apply(EXT1_replace, axis = 1)\n",
    "\n",
    "del male_df\n",
    "del female_df\n",
    "del nogender_df\n",
    "del  r_value, p_value, std_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215541</th>\n",
       "      <td>M</td>\n",
       "      <td>-9244</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277842</th>\n",
       "      <td>F</td>\n",
       "      <td>-19019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196576</th>\n",
       "      <td>M</td>\n",
       "      <td>-12571</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432484</th>\n",
       "      <td>F</td>\n",
       "      <td>-17191</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299977</th>\n",
       "      <td>F</td>\n",
       "      <td>-18594</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CODE_GENDER  DAYS_BIRTH  EXT_SOURCE_1\n",
       "SK_ID_CURR                                      \n",
       "215541               M       -9244           NaN\n",
       "277842               F      -19019           NaN\n",
       "196576               M      -12571           NaN\n",
       "432484               F      -17191           NaN\n",
       "299977               F      -18594           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215541</th>\n",
       "      <td>M</td>\n",
       "      <td>-9244</td>\n",
       "      <td>0.255355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277842</th>\n",
       "      <td>F</td>\n",
       "      <td>-19019</td>\n",
       "      <td>0.667924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196576</th>\n",
       "      <td>M</td>\n",
       "      <td>-12571</td>\n",
       "      <td>0.360291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432484</th>\n",
       "      <td>F</td>\n",
       "      <td>-17191</td>\n",
       "      <td>0.612460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299977</th>\n",
       "      <td>F</td>\n",
       "      <td>-18594</td>\n",
       "      <td>0.655029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CODE_GENDER  DAYS_BIRTH  EXT_SOURCE_1\n",
       "SK_ID_CURR                                      \n",
       "215541               M       -9244      0.255355\n",
       "277842               F      -19019      0.667924\n",
       "196576               M      -12571      0.360291\n",
       "432484               F      -17191      0.612460\n",
       "299977               F      -18594      0.655029"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check \n",
    "display(test_1)\n",
    "display(application_train_df.loc[test_1.index.values, ['CODE_GENDER','DAYS_BIRTH','EXT_SOURCE_1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     13
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# this is a bit slow, but faster than only applying to nan values and then replacing in a loop \n",
    "r1_df = application_train_df[application_train_df['REGION_RATING_CLIENT']==1][['DAYS_BIRTH','EXT_SOURCE_2']]\n",
    "r1_df = r1_df[r1_df['EXT_SOURCE_2'].notna()]\n",
    "r1_s, r1_i, r_value, p_value, std_err = stats.linregress(r1_df)\n",
    "\n",
    "r2_df = application_train_df[application_train_df['REGION_RATING_CLIENT']==2][['DAYS_BIRTH','EXT_SOURCE_2']]\n",
    "r2_df = r2_df[r2_df['EXT_SOURCE_2'].notna()]\n",
    "r2_s, r2_i, r_value, p_value, std_err = stats.linregress(r2_df)\n",
    "\n",
    "r3_df = application_train_df[application_train_df['REGION_RATING_CLIENT']==3][['DAYS_BIRTH','EXT_SOURCE_2']]\n",
    "r3_df = r3_df[r3_df['EXT_SOURCE_2'].notna()]\n",
    "r3_s, r3_i, r_value, p_value, std_err = stats.linregress(r3_df)\n",
    "\n",
    "def EXT2_replace(row):\n",
    "    if np.isnan(row['EXT_SOURCE_2']) ==False:\n",
    "        return row['EXT_SOURCE_2']\n",
    "    else:\n",
    "        if row['REGION_RATING_CLIENT']==1:\n",
    "            return r1_s*row['DAYS_BIRTH'] + r1_i\n",
    "        if row['REGION_RATING_CLIENT']==2:\n",
    "            return r2_s*row['DAYS_BIRTH'] + r2_i\n",
    "        if row['REGION_RATING_CLIENT']==3:\n",
    "            return r3_s*row['DAYS_BIRTH'] + r3_i\n",
    "    \n",
    "application_train_df['EXT_SOURCE_2'] = application_train_df.apply(EXT2_replace, axis = 1)\n",
    "\n",
    "del r1_df, r2_df, r3_df\n",
    "del r_value, p_value, std_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254814</th>\n",
       "      <td>2</td>\n",
       "      <td>-18864</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350771</th>\n",
       "      <td>1</td>\n",
       "      <td>-13779</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285738</th>\n",
       "      <td>2</td>\n",
       "      <td>-24475</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437408</th>\n",
       "      <td>3</td>\n",
       "      <td>-14783</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335830</th>\n",
       "      <td>2</td>\n",
       "      <td>-10766</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            REGION_RATING_CLIENT  DAYS_BIRTH  EXT_SOURCE_2\n",
       "SK_ID_CURR                                                \n",
       "254814                         2      -18864           NaN\n",
       "350771                         1      -13779           NaN\n",
       "285738                         2      -24475           NaN\n",
       "437408                         3      -14783           NaN\n",
       "335830                         2      -10766           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254814</th>\n",
       "      <td>2</td>\n",
       "      <td>-18864</td>\n",
       "      <td>0.527566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350771</th>\n",
       "      <td>1</td>\n",
       "      <td>-13779</td>\n",
       "      <td>0.631082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285738</th>\n",
       "      <td>2</td>\n",
       "      <td>-24475</td>\n",
       "      <td>0.548885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437408</th>\n",
       "      <td>3</td>\n",
       "      <td>-14783</td>\n",
       "      <td>0.413344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335830</th>\n",
       "      <td>2</td>\n",
       "      <td>-10766</td>\n",
       "      <td>0.496797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            REGION_RATING_CLIENT  DAYS_BIRTH  EXT_SOURCE_2\n",
       "SK_ID_CURR                                                \n",
       "254814                         2      -18864      0.527566\n",
       "350771                         1      -13779      0.631082\n",
       "285738                         2      -24475      0.548885\n",
       "437408                         3      -14783      0.413344\n",
       "335830                         2      -10766      0.496797"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check\n",
    "display(test_2)\n",
    "display(application_train_df.loc[test_2.index.values,['REGION_RATING_CLIENT','DAYS_BIRTH','EXT_SOURCE_2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     5
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# this is a bit slow, but faster than only applying to nan values and then replacing in a loop \n",
    "e3_df = application_train_df[['DAYS_BIRTH','EXT_SOURCE_3']]\n",
    "e3_df = e3_df[e3_df['EXT_SOURCE_3'].notna()]\n",
    "e3_s, e3_i, r_value, p_value, std_err = stats.linregress(e3_df)\n",
    "\n",
    "def EXT3_replace(row):\n",
    "    if np.isnan(row['EXT_SOURCE_3']) ==False:\n",
    "        return row['EXT_SOURCE_3']\n",
    "    else:\n",
    "        return e3_s*row['DAYS_BIRTH'] + e3_i\n",
    "    \n",
    "application_train_df['EXT_SOURCE_3'] = application_train_df.apply(EXT3_replace, axis = 1)\n",
    "\n",
    "del e3_df\n",
    "del r_value, p_value, std_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339375</th>\n",
       "      <td>-13796</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175526</th>\n",
       "      <td>-14767</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400503</th>\n",
       "      <td>-10197</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450576</th>\n",
       "      <td>-20177</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335597</th>\n",
       "      <td>-14154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DAYS_BIRTH  EXT_SOURCE_3\n",
       "SK_ID_CURR                          \n",
       "339375          -13796           NaN\n",
       "175526          -14767           NaN\n",
       "400503          -10197           NaN\n",
       "450576          -20177           NaN\n",
       "335597          -14154           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339375</th>\n",
       "      <td>-13796</td>\n",
       "      <td>0.489097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175526</th>\n",
       "      <td>-14767</td>\n",
       "      <td>0.498140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400503</th>\n",
       "      <td>-10197</td>\n",
       "      <td>0.455581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450576</th>\n",
       "      <td>-20177</td>\n",
       "      <td>0.548521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335597</th>\n",
       "      <td>-14154</td>\n",
       "      <td>0.492431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DAYS_BIRTH  EXT_SOURCE_3\n",
       "SK_ID_CURR                          \n",
       "339375          -13796      0.489097\n",
       "175526          -14767      0.498140\n",
       "400503          -10197      0.455581\n",
       "450576          -20177      0.548521\n",
       "335597          -14154      0.492431"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check\n",
    "display(test_3)\n",
    "display(application_train_df.loc[test_3.index.values,['DAYS_BIRTH','EXT_SOURCE_3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET                         False\n",
       "NAME_CONTRACT_TYPE             False\n",
       "CODE_GENDER                    False\n",
       "FLAG_OWN_CAR                   False\n",
       "FLAG_OWN_REALTY                False\n",
       "CNT_CHILDREN                   False\n",
       "AMT_INCOME_TOTAL               False\n",
       "AMT_CREDIT                     False\n",
       "AMT_ANNUITY_from_app_train     False\n",
       "AMT_GOODS_PRICE                False\n",
       "NAME_EDUCATION_TYPE            False\n",
       "NAME_FAMILY_STATUS             False\n",
       "REGION_POPULATION_RELATIVE     False\n",
       "DAYS_BIRTH                     False\n",
       "DAYS_EMPLOYED                  False\n",
       "DAYS_REGISTRATION              False\n",
       "DAYS_ID_PUBLISH                False\n",
       "OWN_CAR_AGE                    False\n",
       "FLAG_EMP_PHONE                 False\n",
       "FLAG_WORK_PHONE                False\n",
       "FLAG_PHONE                     False\n",
       "FLAG_EMAIL                     False\n",
       "CNT_FAM_MEMBERS                False\n",
       "REGION_RATING_CLIENT           False\n",
       "WEEKDAY_APPR_PROCESS_START     False\n",
       "HOUR_APPR_PROCESS_START        False\n",
       "REG_REGION_NOT_LIVE_REGION     False\n",
       "REG_REGION_NOT_WORK_REGION     False\n",
       "LIVE_REGION_NOT_WORK_REGION    False\n",
       "REG_CITY_NOT_LIVE_CITY         False\n",
       "REG_CITY_NOT_WORK_CITY         False\n",
       "LIVE_CITY_NOT_WORK_CITY        False\n",
       "EXT_SOURCE_1                   False\n",
       "EXT_SOURCE_2                   False\n",
       "EXT_SOURCE_3                   False\n",
       "APARTMENTS_AVG                 False\n",
       "LANDAREA_AVG                   False\n",
       "TOTALAREA_MODE                 False\n",
       "EMERGENCYSTATE_MODE            False\n",
       "OBS_60_CNT_SOCIAL_CIRCLE       False\n",
       "DAYS_LAST_PHONE_CHANGE         False\n",
       "FLAG_DOCUMENT_3                False\n",
       "FLAG_DOCUMENT_6                False\n",
       "AMT_REQ_CREDIT_BUREAU_YEAR     False\n",
       "NULL_COUNTS                    False\n",
       "SOCIAL_NULL_COUNTS             False\n",
       "NAME_TYPE_SUITE_condensed      False\n",
       "NAME_INCOME_TYPE_condensed     False\n",
       "NAME_HOUSING_TYPE_condensed    False\n",
       "OCCUPATION_TYPE_condensed      False\n",
       "ORGANIZATION_TYPE_condensed    False\n",
       "DAYS_EMPLOYED_eq_365243        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_train_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## create new features (log and pwr of continuous features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# these were explored in plots in a separate notebook\n",
    "\n",
    "this_feat = 'AMT_INCOME_TOTAL'\n",
    "application_train_df['log_'+this_feat] = np.log10( application_train_df[this_feat] + 1 ) \n",
    "\n",
    "this_feat = 'AMT_CREDIT'\n",
    "application_train_df['log_'+this_feat] = np.log10( application_train_df[this_feat] + 1 ) \n",
    "\n",
    "this_feat = 'AMT_ANNUITY_from_app_train'\n",
    "application_train_df['pwr_'+this_feat] = (application_train_df[this_feat])**(1/4)\n",
    "\n",
    "this_feat = 'AMT_GOODS_PRICE'\n",
    "application_train_df['log_'+this_feat] = np.log10( application_train_df[this_feat] + 1 ) \n",
    "\n",
    "this_feat = 'REGION_POPULATION_RELATIVE'\n",
    "application_train_df['pwr_'+this_feat] = (application_train_df[this_feat])**(1/4)\n",
    "\n",
    "this_feat = 'DAYS_REGISTRATION' \n",
    "application_train_df['pwr_'+this_feat] = (-application_train_df[this_feat])**(1/2)\n",
    "\n",
    "this_feat = 'OWN_CAR_AGE'\n",
    "application_train_df['pwr_'+this_feat] = (+application_train_df[this_feat])**(1/2)\n",
    "\n",
    "this_feat = 'DAYS_LAST_PHONE_CHANGE'\n",
    "application_train_df['pwr_'+this_feat] = (-application_train_df[this_feat])**(1/2)\n",
    "\n",
    "this_feat = 'DAYS_EMPLOYED'\n",
    "application_train_df['pwr_'+this_feat] = (-application_train_df[this_feat])**(1/8)\n",
    "\n",
    "this_feat = 'DAYS_ID_PUBLISH'\n",
    "application_train_df['pwr_'+this_feat] = (-application_train_df[this_feat])**(1/1.8)\n",
    " \n",
    "feats_do_drop = ['AMT_INCOME_TOTAL',\n",
    "                 'AMT_CREDIT',\n",
    "                 'AMT_ANNUITY_from_app_train',\n",
    "                 'AMT_GOODS_PRICE',\n",
    "                 'REGION_POPULATION_RELATIVE',\n",
    "                 'DAYS_REGISTRATION',\n",
    "                 'OWN_CAR_AGE',\n",
    "                 'DAYS_LAST_PHONE_CHANGE',\n",
    "                 'DAYS_EMPLOYED',\n",
    "                 'DAYS_ID_PUBLISH',\n",
    "                  ]\n",
    "\n",
    "application_train_df.drop(columns=feats_do_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET                            False\n",
       "NAME_CONTRACT_TYPE                False\n",
       "CODE_GENDER                       False\n",
       "FLAG_OWN_CAR                      False\n",
       "FLAG_OWN_REALTY                   False\n",
       "CNT_CHILDREN                      False\n",
       "NAME_EDUCATION_TYPE               False\n",
       "NAME_FAMILY_STATUS                False\n",
       "DAYS_BIRTH                        False\n",
       "FLAG_EMP_PHONE                    False\n",
       "FLAG_WORK_PHONE                   False\n",
       "FLAG_PHONE                        False\n",
       "FLAG_EMAIL                        False\n",
       "CNT_FAM_MEMBERS                   False\n",
       "REGION_RATING_CLIENT              False\n",
       "WEEKDAY_APPR_PROCESS_START        False\n",
       "HOUR_APPR_PROCESS_START           False\n",
       "REG_REGION_NOT_LIVE_REGION        False\n",
       "REG_REGION_NOT_WORK_REGION        False\n",
       "LIVE_REGION_NOT_WORK_REGION       False\n",
       "REG_CITY_NOT_LIVE_CITY            False\n",
       "REG_CITY_NOT_WORK_CITY            False\n",
       "LIVE_CITY_NOT_WORK_CITY           False\n",
       "EXT_SOURCE_1                      False\n",
       "EXT_SOURCE_2                      False\n",
       "EXT_SOURCE_3                      False\n",
       "APARTMENTS_AVG                    False\n",
       "LANDAREA_AVG                      False\n",
       "TOTALAREA_MODE                    False\n",
       "EMERGENCYSTATE_MODE               False\n",
       "OBS_60_CNT_SOCIAL_CIRCLE          False\n",
       "FLAG_DOCUMENT_3                   False\n",
       "FLAG_DOCUMENT_6                   False\n",
       "AMT_REQ_CREDIT_BUREAU_YEAR        False\n",
       "NULL_COUNTS                       False\n",
       "SOCIAL_NULL_COUNTS                False\n",
       "NAME_TYPE_SUITE_condensed         False\n",
       "NAME_INCOME_TYPE_condensed        False\n",
       "NAME_HOUSING_TYPE_condensed       False\n",
       "OCCUPATION_TYPE_condensed         False\n",
       "ORGANIZATION_TYPE_condensed       False\n",
       "DAYS_EMPLOYED_eq_365243           False\n",
       "log_AMT_INCOME_TOTAL              False\n",
       "log_AMT_CREDIT                    False\n",
       "pwr_AMT_ANNUITY_from_app_train    False\n",
       "log_AMT_GOODS_PRICE               False\n",
       "pwr_REGION_POPULATION_RELATIVE    False\n",
       "pwr_DAYS_REGISTRATION             False\n",
       "pwr_OWN_CAR_AGE                   False\n",
       "pwr_DAYS_LAST_PHONE_CHANGE        False\n",
       "pwr_DAYS_EMPLOYED                 False\n",
       "pwr_DAYS_ID_PUBLISH               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_train_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_df.to_csv(save_path + 'application_train_df_cleaned_final.csv', columns = list(application_train_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del application_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# bureau wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_feats = ['SK_ID_CURR',\n",
    "              'CREDIT_CURRENCY_mode', \n",
    "              'CREDIT_ACTIVE_mode', \n",
    "              'CREDIT_TYPE_mode',\n",
    "              'DAYS_CREDIT_min',\n",
    "              'DAYS_CREDIT_mean',\n",
    "              'DAYS_ENDDATE_FACT_min',\n",
    "              'DAYS_CREDIT_median',\n",
    "              'DAYS_ENDDATE_FACT_median',\n",
    "            # 'AMT_ANNUITY_from_bureau_mean', # this doesn't have enough non null vals\n",
    "              'AMT_CREDIT_SUM_DEBT_mean',\n",
    "              'DAYS_CREDIT_ENDDATE_mean', \n",
    "              'DAYS_CREDIT_UPDATE_mean'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bureau_df_aggregated_final_df = pd.read_csv(agg_data_path + 'bureau_df_aggregated_final.csv', index_col='SK_ID_CURR', usecols=best_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 307511 entries, 100002 to 456255\n",
      "Data columns (total 11 columns):\n",
      "DAYS_CREDIT_ENDDATE_mean    261242 non-null float64\n",
      "DAYS_ENDDATE_FACT_median    230355 non-null float64\n",
      "DAYS_ENDDATE_FACT_min       230355 non-null float64\n",
      "AMT_CREDIT_SUM_DEBT_mean    256131 non-null float64\n",
      "DAYS_CREDIT_mean            263491 non-null float64\n",
      "DAYS_CREDIT_median          263491 non-null float64\n",
      "DAYS_CREDIT_min             263491 non-null float64\n",
      "DAYS_CREDIT_UPDATE_mean     263491 non-null float64\n",
      "CREDIT_ACTIVE_mode          263491 non-null object\n",
      "CREDIT_CURRENCY_mode        263491 non-null object\n",
      "CREDIT_TYPE_mode            263491 non-null object\n",
      "dtypes: float64(8), object(3)\n",
      "memory usage: 28.2+ MB\n"
     ]
    }
   ],
   "source": [
    "bureau_df_aggregated_final_df.info(verbose = True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# replace NaNs in object entries for now is pretty safe. \n",
    "f_list = list(bureau_df_aggregated_final_df.select_dtypes('object').columns)\n",
    "bureau_df_aggregated_final_df[f_list] = bureau_df_aggregated_final_df[f_list].fillna(value = 'No/Av')\n",
    "del f_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for categorical feature than have more than one value <1%, condensed the <1% values and define a new condensed feature\n",
    "\n",
    "for feat in bureau_df_aggregated_final_df.select_dtypes('object').columns:\n",
    "    percent_srs = bureau_df_aggregated_final_df[feat].value_counts() /len(bureau_df_aggregated_final_df[feat])\n",
    "    percent_less_than_1 = list(percent_srs[percent_srs <.01].index)\n",
    "    if len(percent_less_than_1)>1:\n",
    "        bureau_df_aggregated_final_df[feat + '_condensed'] = bureau_df_aggregated_final_df[feat].apply(lambda x: '<1%' if x in percent_less_than_1 else x)\n",
    "        bureau_df_aggregated_final_df.drop(columns=[feat], inplace=True)\n",
    "      \n",
    "del feat\n",
    "del percent_srs\n",
    "del percent_less_than_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def log_modulus_transformation(x):\n",
    "    return np.sign(x)*np.log10( np.abs(x)+1)\n",
    "\n",
    "def pwr_transformation(x,pwr):\n",
    "    return np.sign(x)*( np.abs(x) )**pwr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TRANSFORMATIONS, then drop original features. \n",
    "\n",
    "bureau_df_aggregated_final_df['pwr_DAYS_CREDIT_mean'] = pwr_transformation(bureau_df_aggregated_final_df['DAYS_CREDIT_mean'], 1/1.7)\n",
    "bureau_df_aggregated_final_df['pwr_DAYS_ENDDATE_FACT_min'] = pwr_transformation(bureau_df_aggregated_final_df['DAYS_ENDDATE_FACT_min'],1/1.3)\n",
    "bureau_df_aggregated_final_df['pwr_DAYS_CREDIT_median'] = pwr_transformation(bureau_df_aggregated_final_df['DAYS_CREDIT_median'],1/2)\n",
    "bureau_df_aggregated_final_df['pwr_DAYS_ENDDATE_FACT_median'] = pwr_transformation(bureau_df_aggregated_final_df['DAYS_ENDDATE_FACT_median'],1/2)\n",
    "bureau_df_aggregated_final_df['LogMod_AMT_CREDIT_SUM_DEBT_mean'] = log_modulus_transformation(bureau_df_aggregated_final_df['AMT_CREDIT_SUM_DEBT_mean'])\n",
    "bureau_df_aggregated_final_df['pwr_DAYS_CREDIT_ENDDATE_mean'] = pwr_transformation(bureau_df_aggregated_final_df['DAYS_CREDIT_ENDDATE_mean'], .65)\n",
    "bureau_df_aggregated_final_df['pwr_DAYS_CREDIT_UPDATE_mean'] = pwr_transformation(bureau_df_aggregated_final_df['DAYS_CREDIT_UPDATE_mean'],.2)\n",
    "\n",
    "bureau_df_aggregated_final_df.drop(columns=['DAYS_CREDIT_mean',\n",
    "                                            'DAYS_ENDDATE_FACT_min',                                            \n",
    "                                            'DAYS_CREDIT_median',\n",
    "                                            'DAYS_ENDDATE_FACT_median',   \n",
    "                                            'AMT_CREDIT_SUM_DEBT_mean',\n",
    "                                            'DAYS_CREDIT_ENDDATE_mean',\n",
    "                                            'DAYS_CREDIT_UPDATE_mean',\n",
    "                                            ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "replace_dict = {'DAYS_CREDIT_min':-1262,\n",
    "                'pwr_DAYS_CREDIT_mean':54,\n",
    "                'pwr_DAYS_ENDDATE_FACT_min':134,\n",
    "                'pwr_DAYS_CREDIT_median':26,\n",
    "                'pwr_DAYS_ENDDATE_FACT_median':22,\n",
    "                'LogMod_AMT_CREDIT_SUM_DEBT_mean':bureau_df_aggregated_final_df['LogMod_AMT_CREDIT_SUM_DEBT_mean'].median(),\n",
    "                'pwr_DAYS_CREDIT_ENDDATE_mean':0,\n",
    "                'pwr_DAYS_CREDIT_UPDATE_mean':-3.23,    \n",
    "                }\n",
    "\n",
    "bureau_df_aggregated_final_df.fillna(replace_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 307511 entries, 100002 to 456255\n",
      "Data columns (total 11 columns):\n",
      "DAYS_CREDIT_min                    307511 non-null float64\n",
      "CREDIT_ACTIVE_mode                 307511 non-null object\n",
      "CREDIT_CURRENCY_mode_condensed     307511 non-null object\n",
      "CREDIT_TYPE_mode_condensed         307511 non-null object\n",
      "pwr_DAYS_CREDIT_mean               307511 non-null float64\n",
      "pwr_DAYS_ENDDATE_FACT_min          307511 non-null float64\n",
      "pwr_DAYS_CREDIT_median             307511 non-null float64\n",
      "pwr_DAYS_ENDDATE_FACT_median       307511 non-null float64\n",
      "LogMod_AMT_CREDIT_SUM_DEBT_mean    307511 non-null float64\n",
      "pwr_DAYS_CREDIT_ENDDATE_mean       307511 non-null float64\n",
      "pwr_DAYS_CREDIT_UPDATE_mean        307511 non-null float64\n",
      "dtypes: float64(8), object(3)\n",
      "memory usage: 28.2+ MB\n"
     ]
    }
   ],
   "source": [
    "bureau_df_aggregated_final_df.info(verbose = True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bureau_df_aggregated_final_df.to_csv(save_path + 'bureau_df_aggregated_wrangled_final.csv', columns = list(bureau_df_aggregated_final_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del bureau_df_aggregated_final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# installments payments wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feats = ['SK_ID_CURR',\n",
    "              'NUM_OF_LOANS',\n",
    "              'DAYS_PAYMENT_LATE_median',\n",
    "              'DAYS_PAYMENT_LATE_sd',\n",
    "              'NUM_TIMES_LATE',\n",
    "              'NUM_TIMES_EARLY',\n",
    "              'AMT_OVERPAY_MEAN',\n",
    "              'AMT_OVERPAY_SD',\n",
    "              'NUM_TIMES_OVERPAY',\n",
    "              'TERMS_CHANGE_TIMES',\n",
    "              'NUM_INSTALMENT_VERSION_max',\n",
    "              'NUM_INSTALMENT_VERSION_min',\n",
    "              'DAYS_INSTALMENT_mean',\n",
    "              'DAYS_INSTALMENT_min',\n",
    "              'DAYS_ENTRY_PAYMENT_mean',\n",
    "              'DAYS_ENTRY_PAYMENT_min',\n",
    "              'AMT_INSTALMENT_mean',\n",
    "              'AMT_INSTALMENT_max',\n",
    "              'AMT_INSTALMENT_min',\n",
    "              'AMT_PAYMENT_mean',\n",
    "              'AMT_PAYMENT_max',\n",
    "              'AMT_PAYMENT_min',\n",
    "              'NUM_INSTALMENT_NUMBER_mean',\n",
    "              'NUM_INSTALMENT_NUMBER_max',\n",
    "             ]            \n",
    "              \n",
    "#               'NUM_INSTALMENT_VERSION_min',\n",
    "#               'DAYS_INSTALMENT_mean',\n",
    "#               'DAYS_INSTALMENT_min',\n",
    "#               'DAYS_ENTRY_PAYMENT_median',\n",
    "#               'DAYS_ENTRY_PAYMENT_min',\n",
    "#               'AMT_INSTALMENT_mean',\n",
    "#               'AMT_INSTALMENT_max',\n",
    "#               'AMT_INSTALMENT_min',\n",
    "#               'AMT_PAYMENT_mean',\n",
    "#               'AMT_PAYMENT_max',\n",
    "#               'AMT_PAYMENT_min',\n",
    "#               'NUM_INSTALMENT_NUMBER_mean',\n",
    "#             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments_payments_df_agg_final = pd.read_csv(agg_data_path + 'installments_payments_df_final.csv', index_col='SK_ID_CURR', usecols=best_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 307511 entries, 100002 to 456255\n",
      "Data columns (total 23 columns):\n",
      "NUM_OF_LOANS                  291643 non-null float64\n",
      "DAYS_PAYMENT_LATE_median      291635 non-null float64\n",
      "DAYS_PAYMENT_LATE_sd          290947 non-null float64\n",
      "NUM_TIMES_LATE                291643 non-null float64\n",
      "NUM_TIMES_EARLY               291643 non-null float64\n",
      "AMT_OVERPAY_MEAN              290913 non-null float64\n",
      "AMT_OVERPAY_SD                290229 non-null float64\n",
      "NUM_TIMES_OVERPAY             291643 non-null float64\n",
      "TERMS_CHANGE_TIMES            291643 non-null float64\n",
      "NUM_INSTALMENT_VERSION_max    291643 non-null float64\n",
      "NUM_INSTALMENT_VERSION_min    291643 non-null float64\n",
      "DAYS_INSTALMENT_mean          291643 non-null float64\n",
      "DAYS_INSTALMENT_min           291643 non-null float64\n",
      "DAYS_ENTRY_PAYMENT_mean       291635 non-null float64\n",
      "DAYS_ENTRY_PAYMENT_min        291635 non-null float64\n",
      "AMT_INSTALMENT_mean           291643 non-null float64\n",
      "AMT_INSTALMENT_max            291643 non-null float64\n",
      "AMT_INSTALMENT_min            291643 non-null float64\n",
      "AMT_PAYMENT_mean              291635 non-null float64\n",
      "AMT_PAYMENT_max               291635 non-null float64\n",
      "AMT_PAYMENT_min               291635 non-null float64\n",
      "NUM_INSTALMENT_NUMBER_mean    291643 non-null float64\n",
      "NUM_INSTALMENT_NUMBER_max     291643 non-null float64\n",
      "dtypes: float64(23)\n",
      "memory usage: 56.3 MB\n"
     ]
    }
   ],
   "source": [
    "installments_payments_df_agg_final.info(verbose = True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_modulus_transformation(x):\n",
    "    return np.sign(x)*np.log10( np.abs(x)+1)\n",
    "\n",
    "def pwr_transformation(x,pwr):\n",
    "    return np.sign(x)*( np.abs(x) )**pwr\n",
    "\n",
    "def transform_drop_replace(df_in, old_feat, trans,  replace_w, exp=0):\n",
    "    \n",
    "    if trans=='pwr':\n",
    "        new_feat = 'pwr_'+ old_feat\n",
    "        df_in[new_feat] = pwr_transformation(df_in[old_feat],exp) \n",
    "        df_in.drop(columns = [old_feat], inplace = True)\n",
    "        \n",
    "        if type(replace_w)==int:\n",
    "            df_in.fillna({new_feat:replace_w}, inplace = True)\n",
    "        elif replace_w == 'median':\n",
    "            df_in.fillna({new_feat:df_in[new_feat].median()}, inplace = True)\n",
    "        elif replace_w == 'mean':\n",
    "            df_in.fillna({new_feat:df_in[new_feat].mean()}, inplace = True)\n",
    "        \n",
    "    if trans=='logmod':\n",
    "        new_feat = 'LogMod_'+ old_feat\n",
    "        df_in[new_feat] = log_modulus_transformation(df_in[old_feat]) \n",
    "        df_in.drop(columns = [old_feat], inplace = True)\n",
    "        \n",
    "        if type(replace_w)==int:\n",
    "            df_in.fillna({new_feat:replace_w}, inplace = True)\n",
    "        elif replace_w == 'median':\n",
    "            df_in.fillna({new_feat:df_in[new_feat].median()}, inplace = True)\n",
    "        elif replace_w == 'mean':\n",
    "            df_in.fillna({new_feat:df_in[new_feat].mean()}, inplace = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMATIONS, then drop original features. \n",
    "\n",
    "\n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat = 'DAYS_PAYMENT_LATE_median', \n",
    "                       trans = 'pwr', \n",
    "                       replace_w = 'median',\n",
    "                       exp = 1/1.7, \n",
    "                      )\n",
    "\n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat ='DAYS_PAYMENT_LATE_sd', \n",
    "                       trans = 'logmod',  \n",
    "                       replace_w = 'median',\n",
    "                       )\n",
    "\n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat ='NUM_TIMES_LATE', \n",
    "                       trans = 'pwr', \n",
    "                       exp = 1/1.5, \n",
    "                       replace_w = 'median')\n",
    "\n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat ='NUM_TIMES_EARLY', \n",
    "                       trans = 'logmod', \n",
    "                       replace_w ='median')\n",
    "\n",
    "\n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat = 'TERMS_CHANGE_TIMES', \n",
    "                       trans = 'pwr', \n",
    "                       exp = 1/2, \n",
    "                       replace_w ='median')\n",
    "\n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat = 'DAYS_INSTALMENT_mean', \n",
    "                       trans = 'pwr', \n",
    "                       exp = 1/3.5, \n",
    "                       replace_w ='median')\n",
    "\n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat ='DAYS_ENTRY_PAYMENT_mean', \n",
    "                       trans = 'pwr', \n",
    "                       exp = 1/3, \n",
    "                       replace_w ='median')\n",
    "                       \n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat = 'AMT_INSTALMENT_mean', \n",
    "                       trans = 'logmod', \n",
    "                       replace_w = 'median')       \n",
    "                       \n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat = 'AMT_INSTALMENT_max', \n",
    "                       trans = 'pwr', \n",
    "                       exp = 1/6, \n",
    "                       replace_w ='median')\n",
    "                       \n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat = 'AMT_INSTALMENT_min', \n",
    "                       trans = 'pwr', \n",
    "                       exp = 1/4, \n",
    "                       replace_w ='median')                       \n",
    "                       \n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat = 'AMT_PAYMENT_mean', \n",
    "                       trans = 'logmod', \n",
    "                       replace_w = 'median')                       \n",
    "\n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat = 'AMT_PAYMENT_max', \n",
    "                       trans = 'logmod', \n",
    "                       replace_w = 'median')                       \n",
    "                       \n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat = 'AMT_PAYMENT_min', \n",
    "                       trans = 'pwr', \n",
    "                       exp =1/5.2, \n",
    "                       replace_w = 'median')                       \n",
    "                       \n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat = 'NUM_INSTALMENT_NUMBER_mean', \n",
    "                       trans = 'logmod', \n",
    "                       replace_w = 'median')                       \n",
    "                       \n",
    "transform_drop_replace(df_in = installments_payments_df_agg_final, \n",
    "                       old_feat = 'NUM_INSTALMENT_NUMBER_max', \n",
    "                       trans = 'logmod', \n",
    "                       replace_w = 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_replace_list=['NUM_OF_LOANS',\n",
    "                        'AMT_OVERPAY_MEAN',\n",
    "                        'AMT_OVERPAY_SD',\n",
    "                        'NUM_TIMES_OVERPAY',\n",
    "                        'NUM_INSTALMENT_VERSION_max',\n",
    "                        'NUM_INSTALMENT_VERSION_min',\n",
    "                        'DAYS_INSTALMENT_min',\n",
    "                        'DAYS_ENTRY_PAYMENT_min', \n",
    "                       ]\n",
    "    \n",
    "for f in remaining_replace_list:\n",
    "    installments_payments_df_agg_final.fillna({f:installments_payments_df_agg_final[f].median()}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 307511 entries, 100002 to 456255\n",
      "Data columns (total 23 columns):\n",
      "NUM_OF_LOANS                         307511 non-null float64\n",
      "AMT_OVERPAY_MEAN                     307511 non-null float64\n",
      "AMT_OVERPAY_SD                       307511 non-null float64\n",
      "NUM_TIMES_OVERPAY                    307511 non-null float64\n",
      "NUM_INSTALMENT_VERSION_max           307511 non-null float64\n",
      "NUM_INSTALMENT_VERSION_min           307511 non-null float64\n",
      "DAYS_INSTALMENT_min                  307511 non-null float64\n",
      "DAYS_ENTRY_PAYMENT_min               307511 non-null float64\n",
      "pwr_DAYS_PAYMENT_LATE_median         307511 non-null float64\n",
      "LogMod_DAYS_PAYMENT_LATE_sd          307511 non-null float64\n",
      "pwr_NUM_TIMES_LATE                   307511 non-null float64\n",
      "LogMod_NUM_TIMES_EARLY               307511 non-null float64\n",
      "pwr_TERMS_CHANGE_TIMES               307511 non-null float64\n",
      "pwr_DAYS_INSTALMENT_mean             307511 non-null float64\n",
      "pwr_DAYS_ENTRY_PAYMENT_mean          307511 non-null float64\n",
      "LogMod_AMT_INSTALMENT_mean           307511 non-null float64\n",
      "pwr_AMT_INSTALMENT_max               307511 non-null float64\n",
      "pwr_AMT_INSTALMENT_min               307511 non-null float64\n",
      "LogMod_AMT_PAYMENT_mean              307511 non-null float64\n",
      "LogMod_AMT_PAYMENT_max               307511 non-null float64\n",
      "pwr_AMT_PAYMENT_min                  307511 non-null float64\n",
      "LogMod_NUM_INSTALMENT_NUMBER_mean    307511 non-null float64\n",
      "LogMod_NUM_INSTALMENT_NUMBER_max     307511 non-null float64\n",
      "dtypes: float64(23)\n",
      "memory usage: 56.3 MB\n"
     ]
    }
   ],
   "source": [
    "installments_payments_df_agg_final.info(verbose = True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments_payments_df_agg_final.to_csv(save_path + 'installments_payments_wrangled_df_final.csv', columns = list(installments_payments_df_agg_final.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "del installments_payments_df_agg_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create final single wrangled CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Desktop/Google Drive/data_science/Python_Projects/Home_Credit_Default_Risk/wrangling/TRAINING_DATA_create_final_wrangled_csv/'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_merge_0 = pd.read_csv(save_path + 'application_train_df_cleaned_final.csv', index_col = 'SK_ID_CURR')\n",
    "df_to_merge_1 = pd.read_csv(save_path + 'bureau_df_aggregated_wrangled_final.csv', index_col = 'SK_ID_CURR')\n",
    "df_to_merge_2 = pd.read_csv(save_path + 'installments_payments_wrangled_df_final.csv', index_col = 'SK_ID_CURR')\n",
    "\n",
    "dfs = (df_to_merge_0,\n",
    "       df_to_merge_1,\n",
    "       df_to_merge_2,\n",
    "       )\n",
    "\n",
    "# these all have the same index (SK_ID_CURR) so no risk for funny business\n",
    "total_df = reduce( lambda left, right: pd.merge( left, right, left_index = True, right_index = True), dfs)\n",
    "# from https://stackoverflow.com/questions/23668427/pandas-joining-multiple-dataframes-on-columns\n",
    "\n",
    "del dfs\n",
    "del df_to_merge_0\n",
    "del df_to_merge_1\n",
    "del df_to_merge_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_df.to_csv(save_path + 'complete_initial_wrangled_data.csv', columns = list(total_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 307511 entries, 100002 to 456255\n",
      "Data columns (total 86 columns):\n",
      "TARGET                               307511 non-null int64\n",
      "NAME_CONTRACT_TYPE                   307511 non-null object\n",
      "CODE_GENDER                          307511 non-null object\n",
      "FLAG_OWN_CAR                         307511 non-null object\n",
      "FLAG_OWN_REALTY                      307511 non-null object\n",
      "CNT_CHILDREN                         307511 non-null int64\n",
      "NAME_EDUCATION_TYPE                  307511 non-null object\n",
      "NAME_FAMILY_STATUS                   307511 non-null object\n",
      "DAYS_BIRTH                           307511 non-null int64\n",
      "FLAG_EMP_PHONE                       307511 non-null int64\n",
      "FLAG_WORK_PHONE                      307511 non-null int64\n",
      "FLAG_PHONE                           307511 non-null int64\n",
      "FLAG_EMAIL                           307511 non-null int64\n",
      "CNT_FAM_MEMBERS                      307511 non-null int64\n",
      "REGION_RATING_CLIENT                 307511 non-null int64\n",
      "WEEKDAY_APPR_PROCESS_START           307511 non-null object\n",
      "HOUR_APPR_PROCESS_START              307511 non-null int64\n",
      "REG_REGION_NOT_LIVE_REGION           307511 non-null int64\n",
      "REG_REGION_NOT_WORK_REGION           307511 non-null int64\n",
      "LIVE_REGION_NOT_WORK_REGION          307511 non-null int64\n",
      "REG_CITY_NOT_LIVE_CITY               307511 non-null int64\n",
      "REG_CITY_NOT_WORK_CITY               307511 non-null int64\n",
      "LIVE_CITY_NOT_WORK_CITY              307511 non-null int64\n",
      "EXT_SOURCE_1                         307511 non-null float64\n",
      "EXT_SOURCE_2                         307511 non-null float64\n",
      "EXT_SOURCE_3                         307511 non-null float64\n",
      "APARTMENTS_AVG                       307511 non-null float64\n",
      "LANDAREA_AVG                         307511 non-null float64\n",
      "TOTALAREA_MODE                       307511 non-null float64\n",
      "EMERGENCYSTATE_MODE                  307511 non-null object\n",
      "OBS_60_CNT_SOCIAL_CIRCLE             307511 non-null float64\n",
      "FLAG_DOCUMENT_3                      307511 non-null int64\n",
      "FLAG_DOCUMENT_6                      307511 non-null int64\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR           307511 non-null float64\n",
      "NULL_COUNTS                          307511 non-null int64\n",
      "SOCIAL_NULL_COUNTS                   307511 non-null int64\n",
      "NAME_TYPE_SUITE_condensed            307511 non-null object\n",
      "NAME_INCOME_TYPE_condensed           307511 non-null object\n",
      "NAME_HOUSING_TYPE_condensed          307511 non-null object\n",
      "OCCUPATION_TYPE_condensed            307511 non-null object\n",
      "ORGANIZATION_TYPE_condensed          307511 non-null object\n",
      "DAYS_EMPLOYED_eq_365243              307511 non-null object\n",
      "log_AMT_INCOME_TOTAL                 307511 non-null float64\n",
      "log_AMT_CREDIT                       307511 non-null float64\n",
      "pwr_AMT_ANNUITY_from_app_train       307511 non-null float64\n",
      "log_AMT_GOODS_PRICE                  307511 non-null float64\n",
      "pwr_REGION_POPULATION_RELATIVE       307511 non-null float64\n",
      "pwr_DAYS_REGISTRATION                307511 non-null float64\n",
      "pwr_OWN_CAR_AGE                      307511 non-null float64\n",
      "pwr_DAYS_LAST_PHONE_CHANGE           307511 non-null float64\n",
      "pwr_DAYS_EMPLOYED                    307511 non-null float64\n",
      "pwr_DAYS_ID_PUBLISH                  307511 non-null float64\n",
      "DAYS_CREDIT_min                      307511 non-null float64\n",
      "CREDIT_ACTIVE_mode                   307511 non-null object\n",
      "CREDIT_CURRENCY_mode_condensed       307511 non-null object\n",
      "CREDIT_TYPE_mode_condensed           307511 non-null object\n",
      "pwr_DAYS_CREDIT_mean                 307511 non-null float64\n",
      "pwr_DAYS_ENDDATE_FACT_min            307511 non-null float64\n",
      "pwr_DAYS_CREDIT_median               307511 non-null float64\n",
      "pwr_DAYS_ENDDATE_FACT_median         307511 non-null float64\n",
      "LogMod_AMT_CREDIT_SUM_DEBT_mean      307511 non-null float64\n",
      "pwr_DAYS_CREDIT_ENDDATE_mean         307511 non-null float64\n",
      "pwr_DAYS_CREDIT_UPDATE_mean          307511 non-null float64\n",
      "NUM_OF_LOANS                         307511 non-null float64\n",
      "AMT_OVERPAY_MEAN                     307511 non-null float64\n",
      "AMT_OVERPAY_SD                       307511 non-null float64\n",
      "NUM_TIMES_OVERPAY                    307511 non-null float64\n",
      "NUM_INSTALMENT_VERSION_max           307511 non-null float64\n",
      "NUM_INSTALMENT_VERSION_min           307511 non-null float64\n",
      "DAYS_INSTALMENT_min                  307511 non-null float64\n",
      "DAYS_ENTRY_PAYMENT_min               307511 non-null float64\n",
      "pwr_DAYS_PAYMENT_LATE_median         307511 non-null float64\n",
      "LogMod_DAYS_PAYMENT_LATE_sd          307511 non-null float64\n",
      "pwr_NUM_TIMES_LATE                   307511 non-null float64\n",
      "LogMod_NUM_TIMES_EARLY               307511 non-null float64\n",
      "pwr_TERMS_CHANGE_TIMES               307511 non-null float64\n",
      "pwr_DAYS_INSTALMENT_mean             307511 non-null float64\n",
      "pwr_DAYS_ENTRY_PAYMENT_mean          307511 non-null float64\n",
      "LogMod_AMT_INSTALMENT_mean           307511 non-null float64\n",
      "pwr_AMT_INSTALMENT_max               307511 non-null float64\n",
      "pwr_AMT_INSTALMENT_min               307511 non-null float64\n",
      "LogMod_AMT_PAYMENT_mean              307511 non-null float64\n",
      "LogMod_AMT_PAYMENT_max               307511 non-null float64\n",
      "pwr_AMT_PAYMENT_min                  307511 non-null float64\n",
      "LogMod_NUM_INSTALMENT_NUMBER_mean    307511 non-null float64\n",
      "LogMod_NUM_INSTALMENT_NUMBER_max     307511 non-null float64\n",
      "dtypes: float64(49), int64(20), object(17)\n",
      "memory usage: 214.1+ MB\n"
     ]
    }
   ],
   "source": [
    "total_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "823px",
    "left": "1572px",
    "right": "68px",
    "top": "108px",
    "width": "447px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
